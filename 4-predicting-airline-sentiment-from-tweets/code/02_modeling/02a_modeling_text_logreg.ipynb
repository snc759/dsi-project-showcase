{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with Text Only to Predict Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## week 3 imports\n",
    "import missingno as msno     # msno.bar(titanic);  or msno.matrix(titanic);\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Linear and general modeling imports\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.impute import SimpleImputer   # Imputation \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures   # Scale/transform/feature engineering\n",
    "\n",
    "import patsy\n",
    "# y, X = patsy.dmatrices(formula, data=diamonds, return_type='dataframe')\n",
    "\n",
    "# GridSearch and Hyperparameter Tuning\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Logistic and Classification metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "# K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# naive bayes imports\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# SVMs\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "\n",
    "# Import Bagging, Boosting, and Random Forests, and ExtraTrees (Extremely Randomized Trees)\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, AdaBoostClassifier, AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "# NLP imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# nltk.download()  --> Download all, and then restart jupyter lab\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import FreqDist, pos_tag\n",
    "import re\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_day</th>\n",
       "      <th>tweet_month</th>\n",
       "      <th>tweet_hour</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>clean_text_stem</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>clean_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>I didn't today... Must mean I need to take an...</td>\n",
       "      <td>2015-02-24 11:15:48-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>today must mean need take anoth trip</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>it's really aggressive to blast obnoxious \"en...</td>\n",
       "      <td>2015-02-24 11:15:36-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>realli aggress blast obnoxi entertain guest fa...</td>\n",
       "      <td>-0.058824</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>seriously would pay $30 a flight for seats th...</td>\n",
       "      <td>2015-02-24 11:14:33-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>serious would pay 30 flight seat play realli b...</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>yes, nearly every time I fly VX this “ear wor...</td>\n",
       "      <td>2015-02-24 11:13:57-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ye nearli everi time fli vx ear worm go away</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Really missed a prime opportunity for Men Wit...</td>\n",
       "      <td>2015-02-24 11:12:29-08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>realli miss prime opportun men without hat par...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment  retweet_count  \\\n",
       "0           neutral              0   \n",
       "1          negative              0   \n",
       "2          negative              0   \n",
       "3          positive              0   \n",
       "4           neutral              0   \n",
       "\n",
       "                                                text  \\\n",
       "0   I didn't today... Must mean I need to take an...   \n",
       "1   it's really aggressive to blast obnoxious \"en...   \n",
       "2   seriously would pay $30 a flight for seats th...   \n",
       "3   yes, nearly every time I fly VX this “ear wor...   \n",
       "4   Really missed a prime opportunity for Men Wit...   \n",
       "\n",
       "               tweet_created  tweet_day  tweet_month  tweet_hour  \\\n",
       "0  2015-02-24 11:15:48-08:00          1            2          11   \n",
       "1  2015-02-24 11:15:36-08:00          1            2          11   \n",
       "2  2015-02-24 11:14:33-08:00          1            2          11   \n",
       "3  2015-02-24 11:13:57-08:00          1            2          11   \n",
       "4  2015-02-24 11:12:29-08:00          1            2          11   \n",
       "\n",
       "   airline_Delta  airline_Southwest  airline_US Airways  airline_United  \\\n",
       "0              0                  0                   0               0   \n",
       "1              0                  0                   0               0   \n",
       "2              0                  0                   0               0   \n",
       "3              0                  0                   0               0   \n",
       "4              0                  0                   0               0   \n",
       "\n",
       "   airline_Virgin America                                    clean_text_stem  \\\n",
       "0                       1               today must mean need take anoth trip   \n",
       "1                       1  realli aggress blast obnoxi entertain guest fa...   \n",
       "2                       1  serious would pay 30 flight seat play realli b...   \n",
       "3                       1       ye nearli everi time fli vx ear worm go away   \n",
       "4                       1  realli miss prime opportun men without hat par...   \n",
       "\n",
       "   sentiment_score  clean_word_count  \n",
       "0         0.000000                 7  \n",
       "1        -0.058824                10  \n",
       "2        -0.041667                12  \n",
       "3         0.000000                10  \n",
       "4         0.000000                11  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/clean_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    0.710114\n",
       "neutral     0.165570\n",
       "positive    0.124316\n",
       "Name: airline_sentiment, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finds the baseline accuracy\n",
    "df['airline_sentiment'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up X and y\n",
    "X = df['clean_text_stem']\n",
    "y = df['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a pipeline\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the pipe parameters \n",
    "pipe_params = {\n",
    "    'cvec__max_features': [2000, 3000, 4000, 5000],\n",
    "    'cvec__min_df':[1, 2],\n",
    "    'cvec__max_df':[0.90, 0.98],\n",
    "    'cvec__ngram_range':[(1,1), (1,2)],\n",
    "    'logreg__C': [1, 0.1, 0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the GridSearchCV\n",
    "gs = GridSearchCV(pipe, \n",
    "                param_grid=pipe_params,\n",
    "                cv=5, \n",
    "                verbose=1,\n",
    "                n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   35.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=4)]: Done 480 out of 480 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'cvec__max_df': [0.9, 0.98],\n",
       "                         'cvec__max_features': [2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'logreg__C': [1, 0.1, 0.01]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7978986402966626"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8674907292954265, 0.8112717834631071)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1, test1 = gs.score(X_train, y_train), gs.score(X_test, y_test)\n",
    "train1, test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.9,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'logreg__C': 0.1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a pipeline\n",
    "pipe2 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the pipe parameters \n",
    "pipe_params2 = {\n",
    "    'cvec__max_features': [5000, 6000, 7000],\n",
    "    'cvec__min_df':[1],\n",
    "    'cvec__max_df':[0.70, 0.80, 0.90],\n",
    "    'cvec__ngram_range':[(1,2)],\n",
    "    'logreg__C': [0.5, 0.3, 0.1, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the GridSearchCV\n",
    "gs2 = GridSearchCV(pipe2, \n",
    "                param_grid=pipe_params2,\n",
    "                cv=5, \n",
    "                verbose=1,\n",
    "                n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:   47.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'cvec__max_df': [0.7, 0.8, 0.9],\n",
       "                         'cvec__max_features': [5000, 6000, 7000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 2)],\n",
       "                         'logreg__C': [0.5, 0.3, 0.1, 0.05]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9457354758961681, 0.8134964775676677)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2, test2 = gs2.score(X_train, y_train), gs2.score(X_test, y_test)\n",
    "train2, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.7,\n",
       " 'cvec__max_features': 7000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'logreg__C': 0.5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a pipeline\n",
    "pipe3 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the pipe parameters \n",
    "pipe_params3 = {\n",
    "    'cvec__min_df':[1],\n",
    "    'cvec__max_df':[0.60, 0.70, 0.75],\n",
    "    'cvec__ngram_range':[(1,2)],\n",
    "    'logreg__C': [0.6, 0.5, 0.4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the GridSearchCV\n",
    "gs3 = GridSearchCV(pipe3, \n",
    "                param_grid=pipe_params3,\n",
    "                cv=5, \n",
    "                verbose=1,\n",
    "                n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  45 out of  45 | elapsed:   52.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('logreg', LogisticRegression())]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'cvec__max_df': [0.6, 0.7, 0.75], 'cvec__min_df': [1],\n",
       "                         'cvec__ngram_range': [(1, 2)],\n",
       "                         'logreg__C': [0.6, 0.5, 0.4]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9982694684796044, 0.8164627363737486)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train3, test3 = gs3.score(X_train, y_train), gs3.score(X_test, y_test)\n",
    "train3, test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.6,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'logreg__C': 0.6}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
