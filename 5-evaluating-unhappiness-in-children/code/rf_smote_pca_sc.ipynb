{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Modeling using SMOTE, and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## week 3 imports\n",
    "import missingno as msno     # msno.bar(titanic);  or msno.matrix(titanic);\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Linear and general modeling imports\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.impute import SimpleImputer   # Imputation \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures   # Scale/transform/feature engineering\n",
    "\n",
    "import patsy\n",
    "# y, X = patsy.dmatrices(formula, data=diamonds, return_type='dataframe')\n",
    "\n",
    "# GridSearch and Hyperparameter Tuning\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "########from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Logistic and Classification metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "# K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# naive bayes imports\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# SVMs\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "\n",
    "# Import Bagging, Boosting, and Random Forests, and ExtraTrees (Extremely Randomized Trees)\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, AdaBoostClassifier, AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "# NLP imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# nltk.download()  --> Download all, and then restart jupyter lab\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import FreqDist, pos_tag\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports SMOTE (oversampling) and undersampleing packages \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports library for PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the data\n",
    "df = pd.read_feather('../../data/h201.feather')\n",
    "health_vars = pd.read_csv('../../data/Health Status Variables.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cleaning function to filter df by age, and Unhappiness responses.\n",
    "# Also turns unhappiness target variable into a binary\n",
    "def clean_df(df):\n",
    "    df = df[(df['AGELAST']>=5) & (df['AGELAST']<=17)]\n",
    "    df = df[(df['UNHAP42']>=0) & (df['UNHAP42']<=4)]\n",
    "    df['UNHAP42'] = df['UNHAP42'].map({0:0, 1:1, 2:1, 3:1, 4:1})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the child dataframe to be shaped for modeling\n",
    "shaped_df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines variable groups\n",
    "\n",
    "# children with special health care needs screener variables\n",
    "special_needs = list(health_vars['VARIABLE'][30:45])\n",
    "\n",
    "# columbia impairment scale\n",
    "impairment = list(health_vars['VARIABLE'][45:58])\n",
    "\n",
    "# Consumer Assessment of Healthcare Providers and Systems (CAHPS)\n",
    "cahps = list(health_vars['VARIABLE'][58:72])\n",
    "\n",
    "# Physical features\n",
    "phys = ['CHBMIX42', 'WHNPHY42']\n",
    "\n",
    "\n",
    "# all children variables \n",
    "all_child = list(health_vars['VARIABLE'][30:97])\n",
    "\n",
    "#########\n",
    "# other identifier/demographic variables \n",
    "other = ['AGELAST', 'SEX', 'RACEV2X', 'FAMINC17', 'ADHDADDX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features of special needs children\n",
    "child_feat = all_child + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the dataframe with just the child related features \n",
    "child_df = shaped_df[child_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up X and y\n",
    "X = child_df.drop(columns='UNHAP42')\n",
    "y = child_df['UNHAP42']\n",
    "\n",
    "# X = shaped_df.drop(columns='UNHAP42')\n",
    "# y = shaped_df['UNHAP42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline\n",
    "* Standard Scale\n",
    "* SMOTE over sample\n",
    "* SMOTE under sample\n",
    "* PCA\n",
    "* Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scales \n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape Counter({0: 3267, 1: 2614})\n"
     ]
    }
   ],
   "source": [
    "# Uses SMOTE to over sample minority class and under sample majority class\n",
    "# Instantiates SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.8, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.8, random_state=42)\n",
    "\n",
    "# Resamples the data\n",
    "X_train_sc_res, y_train_res = smote.fit_resample(X_train_sc, y_train)\n",
    "X_train_sc_res, y_train_res = under.fit_resample(X_train_sc_res, y_train_res)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses PCA to reduce dimensionality \n",
    "# Instantiates PCA\n",
    "# pca = PCA(n_components=20)\n",
    "# Z_train = pca.fit_transform(X_train_res)\n",
    "# Z_test = pca.transform(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the Pipeline with PCA and Random Forest\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=307, \n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=2,\n",
    "                                  min_samples_split=3,\n",
    "                                  random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch to find the optimal number of components for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the pipe parameters\n",
    "pipe_params = {\n",
    "    'pca__n_components' : range(1, 20, 4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the gridsearch\n",
    "gs = GridSearchCV(pipe,\n",
    "                  param_grid=pipe_params,\n",
    "                  cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('pca', PCA(n_components=71)),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(max_depth=10,\n",
       "                                                               min_samples_leaf=2,\n",
       "                                                               min_samples_split=3,\n",
       "                                                               n_estimators=307,\n",
       "                                                               random_state=42))]),\n",
       "             param_grid={'pca__n_components': range(1, 20, 4)})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fits data to gridsearch \n",
    "gs.fit(X_train_sc_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8022474410324877"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates gridsearch cross val score\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9103893895595987, 0.7986486486486486)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates gridsearch accuracy scores \n",
    "gs.score(X_train_sc_res, y_train_res), gs.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca__n_components': 17}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finds the best params for the pca number of components\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline with best number of components for PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the Pipeline with PCA and Random Forest\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA(n_components=71)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=307, \n",
    "                                  max_depth=10, \n",
    "                                  min_samples_leaf=2,\n",
    "                                  min_samples_split=3,\n",
    "                                  random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=71)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(max_depth=10, min_samples_leaf=2,\n",
       "                                        min_samples_split=3, n_estimators=307,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fits to the PCA and then Random Forest Model\n",
    "pipe.fit(X_train_sc_res, y_train_res)\n",
    "# pipe.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9488182281924843, 0.8081081081081081)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the accuracy scores\n",
    "pipe.score(X_train_sc_res, y_train_res), pipe.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
