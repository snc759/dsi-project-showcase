{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Modeling with GridSearch Optimized for Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## week 3 imports\n",
    "import missingno as msno     # msno.bar(titanic);  or msno.matrix(titanic);\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Linear and general modeling imports\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.impute import SimpleImputer   # Imputation \n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures   # Scale/transform/feature engineering\n",
    "\n",
    "import patsy\n",
    "# y, X = patsy.dmatrices(formula, data=diamonds, return_type='dataframe')\n",
    "\n",
    "# GridSearch and Hyperparameter Tuning\n",
    "# from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Logistic and Classification metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "# K Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# naive bayes imports\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "# SVMs\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "\n",
    "# Import Bagging, Boosting, and Random Forests, and ExtraTrees (Extremely Randomized Trees)\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor, AdaBoostClassifier, AdaBoostRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "# NLP imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# nltk.download()  --> Download all, and then restart jupyter lab\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import FreqDist, pos_tag\n",
    "import re\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepping the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUID</th>\n",
       "      <th>PID</th>\n",
       "      <th>DUPERSID</th>\n",
       "      <th>PANEL</th>\n",
       "      <th>FAMID31</th>\n",
       "      <th>FAMID42</th>\n",
       "      <th>FAMID53</th>\n",
       "      <th>FAMID17</th>\n",
       "      <th>FAMIDYR</th>\n",
       "      <th>CPSFAMID</th>\n",
       "      <th>...</th>\n",
       "      <th>RXPTR17</th>\n",
       "      <th>RXOTH17</th>\n",
       "      <th>PERWT17F</th>\n",
       "      <th>FAMWT17F</th>\n",
       "      <th>FAMWT17C</th>\n",
       "      <th>SAQWT17F</th>\n",
       "      <th>DIABW17F</th>\n",
       "      <th>CSAQW17F</th>\n",
       "      <th>VARSTR</th>\n",
       "      <th>VARPSU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>10001101</td>\n",
       "      <td>21.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2506.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13494.959896</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>18363.716686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>10001102</td>\n",
       "      <td>21.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12031.802435</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>14279.941801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>10001103</td>\n",
       "      <td>21.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12308.918980</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10001104</td>\n",
       "      <td>21.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12280.755977</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>13651.501535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>10002101</td>\n",
       "      <td>21.0</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6596.640550</td>\n",
       "      <td>7113.635349</td>\n",
       "      <td>7113.635349</td>\n",
       "      <td>7427.265851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1077.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1564 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DUID    PID  DUPERSID  PANEL FAMID31 FAMID42 FAMID53 FAMID17 FAMIDYR  \\\n",
       "0  10001.0  101.0  10001101   21.0       A       A       A       A       A   \n",
       "1  10001.0  102.0  10001102   21.0       A       A       A       A       A   \n",
       "2  10001.0  103.0  10001103   21.0       A       A       A       A       A   \n",
       "3  10001.0  104.0  10001104   21.0       A       A       A       A       A   \n",
       "4  10002.0  101.0  10002101   21.0       A       A       A       A       A   \n",
       "\n",
       "  CPSFAMID  ...  RXPTR17  RXOTH17      PERWT17F      FAMWT17F      FAMWT17C  \\\n",
       "0        A  ...   2506.0      0.0  13494.959896  13651.501535  13651.501535   \n",
       "1        A  ...      0.0      0.0  12031.802435  13651.501535  13651.501535   \n",
       "2        A  ...    135.0      0.0  12308.918980  13651.501535  13651.501535   \n",
       "3        A  ...      0.0      0.0  12280.755977  13651.501535  13651.501535   \n",
       "4        A  ...      0.0      0.0   6596.640550   7113.635349   7113.635349   \n",
       "\n",
       "       SAQWT17F  DIABW17F  CSAQW17F  VARSTR  VARPSU  \n",
       "0  18363.716686       0.0       0.0  1021.0     1.0  \n",
       "1  14279.941801       0.0       0.0  1021.0     1.0  \n",
       "2      0.000000       0.0       0.0  1021.0     1.0  \n",
       "3      0.000000       0.0       0.0  1021.0     1.0  \n",
       "4   7427.265851       0.0       0.0  1077.0     1.0  \n",
       "\n",
       "[5 rows x 1564 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads in the data\n",
    "df = pd.read_feather('../data/h201.feather')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VARIABLE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>Activate</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 40</th>\n",
       "      <th>Unnamed: 41</th>\n",
       "      <th>Unnamed: 42</th>\n",
       "      <th>Unnamed: 43</th>\n",
       "      <th>Unnamed: 44</th>\n",
       "      <th>Unnamed: 45</th>\n",
       "      <th>Unnamed: 46</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>Unnamed: 48</th>\n",
       "      <th>Unnamed: 49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IADLHP31</td>\n",
       "      <td>IADL Screener â€“ RD 3/1</td>\n",
       "      <td>HE 1-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADLHLP31</td>\n",
       "      <td>ADL Screener â€“ RD 3/1</td>\n",
       "      <td>HE 4-6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIDHLP31</td>\n",
       "      <td>Used Assistive Devices â€“ RD 3/1</td>\n",
       "      <td>HE 7-8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WLKLIM31</td>\n",
       "      <td>Limitation in Physical Functioning â€“ RD 3/1</td>\n",
       "      <td>HE 9-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LFTDIF31</td>\n",
       "      <td>Difficulty Lifting 10 Pounds â€“ RD 3/1</td>\n",
       "      <td>HE 11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VARIABLE                                  DESCRIPTION   SOURCE  Activate  \\\n",
       "0  IADLHP31                       IADL Screener â€“ RD 3/1   HE 1-3       0.0   \n",
       "1  ADLHLP31                        ADL Screener â€“ RD 3/1   HE 4-6       0.0   \n",
       "2  AIDHLP31              Used Assistive Devices â€“ RD 3/1   HE 7-8       1.0   \n",
       "3  WLKLIM31  Limitation in Physical Functioning â€“ RD 3/1  HE 9-10       1.0   \n",
       "4  LFTDIF31        Difficulty Lifting 10 Pounds â€“ RD 3/1    HE 11       0.0   \n",
       "\n",
       "   Unnamed: 4  Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
       "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "   ...  Unnamed: 40  Unnamed: 41  Unnamed: 42  Unnamed: 43  Unnamed: 44  \\\n",
       "0  ...          NaN          NaN          NaN          NaN          NaN   \n",
       "1  ...          NaN          NaN          NaN          NaN          NaN   \n",
       "2  ...          NaN          NaN          NaN          NaN          NaN   \n",
       "3  ...          NaN          NaN          NaN          NaN          NaN   \n",
       "4  ...          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "   Unnamed: 45  Unnamed: 46  Unnamed: 47  Unnamed: 48  Unnamed: 49  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loads in health status variables dataframe of variable descriptions\n",
    "deps = pd.read_csv('../data/Health Status Variables.csv')\n",
    "deps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subsets the health status variables for the ones that pertain to children\n",
    "child_vars = list(deps['VARIABLE'][30:97])\n",
    "# child_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a list of other variables we want to add\n",
    "other_vars = ['AGELAST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHPMED42',\n",
       " 'CHPMHB42',\n",
       " 'CHPMCN42',\n",
       " 'CHSERV42',\n",
       " 'CHSRHB42',\n",
       " 'CHSRCN42',\n",
       " 'CHLIMI42',\n",
       " 'CHLIHB42',\n",
       " 'CHLICO42',\n",
       " 'CHTHER42',\n",
       " 'CHTHHB42',\n",
       " 'CHTHCO42',\n",
       " 'CHCOUN42',\n",
       " 'CHEMPB42',\n",
       " 'CSHCN42',\n",
       " 'MOMPRO42',\n",
       " 'DADPRO42',\n",
       " 'UNHAP42',\n",
       " 'SCHLBH42',\n",
       " 'HAVFUN42',\n",
       " 'ADUPRO42',\n",
       " 'NERVAF42',\n",
       " 'SIBPRO42',\n",
       " 'KIDPRO42',\n",
       " 'SPRPRO42',\n",
       " 'SCHPRO42',\n",
       " 'HOMEBH42',\n",
       " 'TRBLE42',\n",
       " 'CHILCR42',\n",
       " 'CHILWW42',\n",
       " 'CHRTCR42',\n",
       " 'CHRTWW42',\n",
       " 'CHAPPT42',\n",
       " 'CHNDCR42',\n",
       " 'CHENEC42',\n",
       " 'CHLIST42',\n",
       " 'CHEXPL42',\n",
       " 'CHRESP42',\n",
       " 'CHPRTM42',\n",
       " 'CHHECR42',\n",
       " 'CHSPEC42',\n",
       " 'CHEYRE42',\n",
       " 'MESHGT42',\n",
       " 'WHNHGT42',\n",
       " 'MESWGT42',\n",
       " 'WHNWGT42',\n",
       " 'CHBMIX42',\n",
       " 'MESVIS42',\n",
       " 'MESBPR42',\n",
       " 'WHNBPR42',\n",
       " 'DENTAL42',\n",
       " 'WHNDEN42',\n",
       " 'EATHLT42',\n",
       " 'WHNEAT42',\n",
       " 'PHYSCL42',\n",
       " 'WHNPHY42',\n",
       " 'SAFEST42',\n",
       " 'WHNSAF42',\n",
       " 'BOOST42',\n",
       " 'WHNBST42',\n",
       " 'LAPBLT42',\n",
       " 'WHNLAP42',\n",
       " 'HELMET42',\n",
       " 'WHNHEL42',\n",
       " 'NOSMOK42',\n",
       " 'WHNSMK42',\n",
       " 'TIMALN42',\n",
       " 'AGELAST']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combines the child variables with additional other variables we want to add\n",
    "child_vars = child_vars + other_vars\n",
    "child_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHPMED42</th>\n",
       "      <th>CHPMHB42</th>\n",
       "      <th>CHPMCN42</th>\n",
       "      <th>CHSERV42</th>\n",
       "      <th>CHSRHB42</th>\n",
       "      <th>CHSRCN42</th>\n",
       "      <th>CHLIMI42</th>\n",
       "      <th>CHLIHB42</th>\n",
       "      <th>CHLICO42</th>\n",
       "      <th>CHTHER42</th>\n",
       "      <th>...</th>\n",
       "      <th>BOOST42</th>\n",
       "      <th>WHNBST42</th>\n",
       "      <th>LAPBLT42</th>\n",
       "      <th>WHNLAP42</th>\n",
       "      <th>HELMET42</th>\n",
       "      <th>WHNHEL42</th>\n",
       "      <th>NOSMOK42</th>\n",
       "      <th>WHNSMK42</th>\n",
       "      <th>TIMALN42</th>\n",
       "      <th>AGELAST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31867</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31870</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31871</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31878</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31879</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6155 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CHPMED42  CHPMHB42  CHPMCN42  CHSERV42  CHSRHB42  CHSRCN42  CHLIMI42  \\\n",
       "2           2.0      -1.0      -1.0       2.0      -1.0      -1.0       2.0   \n",
       "3           1.0       1.0       1.0       2.0      -1.0      -1.0       2.0   \n",
       "9           2.0      -1.0      -1.0       2.0      -1.0      -1.0       2.0   \n",
       "13          1.0       1.0       1.0       2.0      -1.0      -1.0       2.0   \n",
       "14          1.0       1.0       1.0       2.0      -1.0      -1.0       2.0   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31867       2.0      -1.0      -1.0       2.0      -1.0      -1.0       2.0   \n",
       "31870       2.0      -1.0      -1.0       2.0      -1.0      -1.0       2.0   \n",
       "31871       2.0      -1.0      -1.0       2.0      -1.0      -1.0       2.0   \n",
       "31878       2.0      -1.0      -1.0       2.0      -1.0      -1.0       2.0   \n",
       "31879       1.0       1.0       1.0       2.0      -1.0      -1.0       2.0   \n",
       "\n",
       "       CHLIHB42  CHLICO42  CHTHER42  ...  BOOST42  WHNBST42  LAPBLT42  \\\n",
       "2          -1.0      -1.0       2.0  ...     -1.0      -1.0       1.0   \n",
       "3          -1.0      -1.0       2.0  ...     -1.0      -1.0       2.0   \n",
       "9          -1.0      -1.0       2.0  ...      1.0       3.0      -1.0   \n",
       "13         -1.0      -1.0       2.0  ...     -1.0      -1.0       2.0   \n",
       "14         -1.0      -1.0       2.0  ...      2.0      -1.0      -1.0   \n",
       "...         ...       ...       ...  ...      ...       ...       ...   \n",
       "31867      -1.0      -1.0       2.0  ...      2.0      -1.0      -1.0   \n",
       "31870      -1.0      -1.0       2.0  ...      1.0       3.0      -1.0   \n",
       "31871      -1.0      -1.0       2.0  ...      1.0       3.0      -1.0   \n",
       "31878      -1.0      -1.0       2.0  ...     -1.0      -1.0       2.0   \n",
       "31879      -1.0      -1.0       2.0  ...     -1.0      -1.0       2.0   \n",
       "\n",
       "       WHNLAP42  HELMET42  WHNHEL42  NOSMOK42  WHNSMK42  TIMALN42  AGELAST  \n",
       "2           1.0       2.0      -1.0       2.0      -1.0       2.0     17.0  \n",
       "3          -1.0       2.0      -1.0       2.0      -1.0       2.0     14.0  \n",
       "9          -1.0       1.0       1.0       2.0      -1.0      -1.0     10.0  \n",
       "13         -1.0       2.0      -1.0       2.0      -1.0       2.0     12.0  \n",
       "14         -1.0       2.0      -1.0       2.0      -1.0      -1.0     11.0  \n",
       "...         ...       ...       ...       ...       ...       ...      ...  \n",
       "31867      -1.0       2.0      -1.0       1.0       2.0      -1.0      6.0  \n",
       "31870      -1.0       1.0       3.0       1.0       3.0      -1.0      9.0  \n",
       "31871      -1.0       1.0       3.0       1.0       3.0      -1.0      5.0  \n",
       "31878      -1.0       2.0      -1.0       2.0      -1.0       1.0     13.0  \n",
       "31879      -1.0       2.0      -1.0       2.0      -1.0      -1.0     10.0  \n",
       "\n",
       "[6155 rows x 68 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filters the age of children between 5-17\n",
    "child_df = df.loc[(df['AGELAST'] <= 17) & (df['AGELAST'] >= 5), child_vars]\n",
    "child_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0     4358\n",
       " 1.0      879\n",
       " 2.0      499\n",
       "-1.0      195\n",
       " 3.0      119\n",
       " 4.0       65\n",
       "-7.0       19\n",
       "-8.0        8\n",
       "-9.0        7\n",
       " 99.0       6\n",
       "Name: UNHAP42, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks the baseline/class balance of target variable\n",
    "child_df['UNHAP42'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters the target variable to be between 0 and 4\n",
    "hap_filter =(child_df['UNHAP42'] >= 0) & (child_df['UNHAP42'] <= 4)\n",
    "child_df = child_df[hap_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-a1b61958f7cf>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  child_df['UNHAP42'] = child_df['UNHAP42'].map({0:0, 1:1, 2:1, 3:1, 4:1})\n"
     ]
    }
   ],
   "source": [
    "# Re-assigns the response variable into binary classes\n",
    "child_df['UNHAP42'] = child_df['UNHAP42'].map({0:0, 1:1, 2:1, 3:1, 4:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.736149\n",
       "1    0.263851\n",
       "Name: UNHAP42, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rechecks the balance/baseline of the target variable\n",
    "child_df['UNHAP42'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling before balancing classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) All Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up X and y\n",
    "X = child_df.drop(columns='UNHAP42')\n",
    "y = child_df['UNHAP42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates all default classifier models\n",
    "logreg = LogisticRegression(random_state=42, solver='liblinear')   # Adjust solver\n",
    "knn = KNeighborsClassifier()\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree_pruned = DecisionTreeClassifier(max_depth=5,  \n",
    "                                     random_state=42)\n",
    "svc = SVC(random_state=42)\n",
    "bagging = BaggingClassifier(random_state=42, \n",
    "                            n_estimators=100)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_pruned = RandomForestClassifier(max_depth=5,\n",
    "                                   random_state=42)\n",
    "boost = AdaBoostClassifier(n_estimators=100, \n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts all the instantiated classifiers in a list\n",
    "class_list = [logreg, knn, tree, tree_pruned, svc, bagging, rf, rf_pruned, boost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final full classification function\n",
    "def modeling_class(class_list, X=None, y=None, use_split_data=False, standard_scale=False, X_train=None, X_test=None, y_train=None, y_test=None):\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, plot_roc_curve, roc_auc_score, recall_score, precision_score, f1_score, classification_report\n",
    "    \n",
    "    if not use_split_data:\n",
    "    \n",
    "        try:\n",
    "            # train-test-split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                                stratify=y,\n",
    "                                                                random_state=42)\n",
    "            if standard_scale:\n",
    "                sc = StandardScaler()\n",
    "                X_train_sc = sc.fit_transform(X_train)\n",
    "                X_test_sc = sc.transform(X_test)\n",
    "                X_train = pd.DataFrame(X_train_sc, columns=X.columns)\n",
    "                X_test = pd.DataFrame(X_test_sc, columns=X.columns)\n",
    "                print('Used standard scale')\n",
    "        except: \n",
    "            return 'You need to set \"use_split_data\"=True if you want to pass already train-test split X and y'\n",
    "    \n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_auc = []\n",
    "    test_auc = []\n",
    "    f1_train = []\n",
    "    f1_test = []\n",
    "    \n",
    "    test_recall = []\n",
    "\n",
    "    # for each classifier fit and score\n",
    "    for classifier in class_list:\n",
    "        classifier.fit(X_train, y_train)\n",
    "        train_acc.append(classifier.score(X_train, y_train))\n",
    "        test_acc.append(classifier.score(X_test, y_test))\n",
    "        train_auc.append(roc_auc_score(y_true=y_train, y_score=classifier.predict(X_train)))\n",
    "        test_auc.append(roc_auc_score(y_true=y_test, y_score=classifier.predict(X_test)))\n",
    "        f1_train.append(f1_score(y_train, classifier.predict(X_train)))\n",
    "        f1_test.append(f1_score(y_test, classifier.predict(X_test)))\n",
    "        \n",
    "        test_recall.append(recall_score(y_test, classifier.predict(X_test)))\n",
    "    # combine into dataframe\n",
    "    dict_of_list_df = pd.DataFrame({'train_acc': train_acc,\n",
    "                                    'test_acc': test_acc,\n",
    "                                    'train_auc': train_auc,\n",
    "                                    'test_auc': test_auc, \n",
    "                                    'f1_train': f1_train,\n",
    "                                    'f1_test': f1_test,\n",
    "                                    'test_recall': test_recall},\n",
    "                                    index=[str(cl) for cl in class_list])\n",
    "\n",
    "    ####################\n",
    "\n",
    "#     list_of_dicts = []\n",
    "#     for classifier in class_list:\n",
    "#         metrics_dict = {}\n",
    "\n",
    "#         classifier.fit(X_train, y_train)\n",
    "#         metrics_dict['train_acc'] = classifier.score(X_train, y_train)\n",
    "#         metrics_dict['test_acc'] = classifier.score(X_test, y_test)\n",
    "#         metrics_dict['train_auc'] = roc_auc_score(y_true=y_train, y_score=classifier.predict(X_train))\n",
    "#         metrics_dict['test_auc'] = roc_auc_score(y_true=y_test, y_score=classifier.predict(X_test))\n",
    "#         metrics_dict['f1_train'] = f1_score(y_train, classifier.predict(X_train))\n",
    "#         metrics_dict['f1_test'] = f1_score(y_test, classifier.predict(X_test))\n",
    "\n",
    "            \n",
    "\n",
    "#         list_of_dicts.append(metrics_dict)\n",
    "\n",
    "#     list_of_dicts_df = pd.DataFrame(list_of_dicts,\n",
    "#                                     index=[str(cl) for cl in class_list])\n",
    "    \n",
    "    return dict_of_list_df#, list_of_dicts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_acc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression(random_state=42, solver='liblinear')</th>\n",
       "      <td>0.833784</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.728112</td>\n",
       "      <td>0.717713</td>\n",
       "      <td>0.615625</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier()</th>\n",
       "      <td>0.820721</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.692423</td>\n",
       "      <td>0.622089</td>\n",
       "      <td>0.553311</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0.323077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier(random_state=42)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.699388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.556675</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier(max_depth=5, random_state=42)</th>\n",
       "      <td>0.847523</td>\n",
       "      <td>0.822973</td>\n",
       "      <td>0.765902</td>\n",
       "      <td>0.735733</td>\n",
       "      <td>0.672472</td>\n",
       "      <td>0.621387</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC(random_state=42)</th>\n",
       "      <td>0.862838</td>\n",
       "      <td>0.818243</td>\n",
       "      <td>0.763993</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.680985</td>\n",
       "      <td>0.564019</td>\n",
       "      <td>0.446154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingClassifier(n_estimators=100, random_state=42)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.754775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.648951</td>\n",
       "      <td>0.594872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(random_state=42)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.841216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660895</td>\n",
       "      <td>0.587179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier(max_depth=5, random_state=42)</th>\n",
       "      <td>0.857658</td>\n",
       "      <td>0.828378</td>\n",
       "      <td>0.762663</td>\n",
       "      <td>0.720466</td>\n",
       "      <td>0.675565</td>\n",
       "      <td>0.601881</td>\n",
       "      <td>0.492308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier(n_estimators=100, random_state=42)</th>\n",
       "      <td>0.854054</td>\n",
       "      <td>0.847297</td>\n",
       "      <td>0.782105</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.680791</td>\n",
       "      <td>0.617949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    train_acc  test_acc  \\\n",
       "LogisticRegression(random_state=42, solver='lib...   0.833784  0.824324   \n",
       "KNeighborsClassifier()                               0.820721  0.763514   \n",
       "DecisionTreeClassifier(random_state=42)              1.000000  0.762162   \n",
       "DecisionTreeClassifier(max_depth=5, random_stat...   0.847523  0.822973   \n",
       "SVC(random_state=42)                                 0.862838  0.818243   \n",
       "BaggingClassifier(n_estimators=100, random_stat...   1.000000  0.830405   \n",
       "RandomForestClassifier(random_state=42)              1.000000  0.841216   \n",
       "RandomForestClassifier(max_depth=5, random_stat...   0.857658  0.828378   \n",
       "AdaBoostClassifier(n_estimators=100, random_sta...   0.854054  0.847297   \n",
       "\n",
       "                                                    train_auc  test_auc  \\\n",
       "LogisticRegression(random_state=42, solver='lib...   0.728112  0.717713   \n",
       "KNeighborsClassifier()                               0.692423  0.622089   \n",
       "DecisionTreeClassifier(random_state=42)              1.000000  0.699388   \n",
       "DecisionTreeClassifier(max_depth=5, random_stat...   0.765902  0.735733   \n",
       "SVC(random_state=42)                                 0.763993  0.698765   \n",
       "BaggingClassifier(n_estimators=100, random_stat...   1.000000  0.754775   \n",
       "RandomForestClassifier(random_state=42)              1.000000  0.759645   \n",
       "RandomForestClassifier(max_depth=5, random_stat...   0.762663  0.720466   \n",
       "AdaBoostClassifier(n_estimators=100, random_sta...   0.782105  0.773653   \n",
       "\n",
       "                                                    f1_train   f1_test  \\\n",
       "LogisticRegression(random_state=42, solver='lib...  0.615625  0.596273   \n",
       "KNeighborsClassifier()                              0.553311  0.418605   \n",
       "DecisionTreeClassifier(random_state=42)             1.000000  0.556675   \n",
       "DecisionTreeClassifier(max_depth=5, random_stat...  0.672472  0.621387   \n",
       "SVC(random_state=42)                                0.680985  0.564019   \n",
       "BaggingClassifier(n_estimators=100, random_stat...  1.000000  0.648951   \n",
       "RandomForestClassifier(random_state=42)             1.000000  0.660895   \n",
       "RandomForestClassifier(max_depth=5, random_stat...  0.675565  0.601881   \n",
       "AdaBoostClassifier(n_estimators=100, random_sta...  0.694915  0.680791   \n",
       "\n",
       "                                                    test_recall  \n",
       "LogisticRegression(random_state=42, solver='lib...     0.492308  \n",
       "KNeighborsClassifier()                                 0.323077  \n",
       "DecisionTreeClassifier(random_state=42)                0.566667  \n",
       "DecisionTreeClassifier(max_depth=5, random_stat...     0.551282  \n",
       "SVC(random_state=42)                                   0.446154  \n",
       "BaggingClassifier(n_estimators=100, random_stat...     0.594872  \n",
       "RandomForestClassifier(random_state=42)                0.587179  \n",
       "RandomForestClassifier(max_depth=5, random_stat...     0.492308  \n",
       "AdaBoostClassifier(n_estimators=100, random_sta...     0.617949  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Runs the modeling_class function on all the instantiated classifiers in the list, and prints out the scores\n",
    "modeling_class(class_list, use_split_data=True, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the Random Forest Classifier\n",
    "\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "rf_pruned = RandomForestClassifier(max_depth=5,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fits the data to the pruned random forest\n",
    "rf_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8576576576576577, 0.8283783783783784)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the pruned random forest accuracy scores\n",
    "rf_pruned.score(X_train, y_train), rf_pruned.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49230769230769234"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = rf_pruned.predict(X_test)\n",
    "recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Random Forest with GridSearch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates random forest\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the gridsearch params\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 300, 600],\n",
    "    'max_depth': [None, 1, 5, 10, 20],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates the gridsearch\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [None, 1, 5, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4, 5],\n",
       "                         'n_estimators': [100, 300, 600]})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fits the data to the gridsearch model\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9617117117117117, 0.8425675675675676)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluates the grid search scores\n",
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks at the best params for the gridsearch model\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.871160409556314, 0.5897435897435898)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a) Second Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [5, 7, 9, 10, 12, 15],\n",
       "                         'min_samples_leaf': [2], 'min_samples_split': [3],\n",
       "                         'n_estimators': [200, 250, 300, 350]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [200, 250, 300, 350],\n",
    "    'max_depth': [5, 7, 9, 10, 12, 15],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8837837837837837, 0.8398648648648649)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks the accuracy scores from the gridsearch model\n",
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 250}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prints out the best params\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6450511945392492, 0.5435897435897435)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b) Third Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [9, 10, 11], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [3],\n",
       "                         'n_estimators': [280, 290, 300, 310]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [280, 290, 300, 310],\n",
    "    'max_depth': [9, 10, 11],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9335585585585585, 0.8405405405405405)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 300}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7755972696245734, 0.5641025641025641)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c) Fourth Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [7, 8, 9, 10, 11],\n",
       "                         'min_samples_leaf': [2], 'min_samples_split': [3],\n",
       "                         'n_estimators': [300, 310, 315, 320]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [300, 310, 315, 320],\n",
    "    'max_depth': [7, 8, 9, 10, 11],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9094594594594595, 0.8398648648648649)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 315}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7090443686006825, 0.5564102564102564)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d) Fifth Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [10], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [3],\n",
       "                         'n_estimators': [305, 308, 310, 312]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [305, 308, 310, 312],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.922972972972973, 0.8405405405405405)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 310}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7457337883959044, 0.5615384615384615)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3e) Sixth Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [10], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [3],\n",
       "                         'n_estimators': [306, 307, 308, 309, 310]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [306, 307, 308, 309, 310],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9225225225225225, 0.8432432432432433)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 308}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7406143344709898, 0.5641025641025641)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3f) Seventh Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=4,\n",
       "             param_grid={'max_depth': [10], 'min_samples_leaf': [2],\n",
       "                         'min_samples_split': [3], 'n_estimators': [307]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [307],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [3],\n",
    "    'min_samples_leaf': [2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=3,\n",
    "                  verbose=1,\n",
    "                  n_jobs=4)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8441441441441441"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9222972972972973, 0.8385135135135136)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_train, y_train), gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 307}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7431740614334471, 0.558974358974359)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3g) Eigth Iteration with GridSearch Params Adjusted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pruned = RandomForestClassifier(max_depth=10,\n",
    "                                   min_samples_leaf=2,\n",
    "                                   min_samples_split=3,\n",
    "                                   n_estimators=307,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=3,\n",
       "                       n_estimators=307, random_state=42)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.925, 0.8405405405405405)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pruned.score(X_train, y_train), rf_pruned.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7457337883959044, 0.5692307692307692)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall Score \n",
    "preds = gs.predict(X_test)\n",
    "recall_score(y_train, gs.predict(X_train)), recall_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
